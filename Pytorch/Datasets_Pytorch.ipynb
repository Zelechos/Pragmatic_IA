{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Datasets_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQqmGpWRRzVuw2/KKrQ2Xz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zelechos/Pragmatic_IA/blob/master/Pytorch/Datasets_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceQRHT9Qc8f-"
      },
      "source": [
        "# Datasets Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmeawYcQct__"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCTAcoktdM3y"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "\n",
        "# descarga datos\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "\n",
        "X, Y = mnist[\"data\"], mnist[\"target\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = X[:60000] / 255., X[60000:] / 255., Y[:60000].astype(np.int), Y[60000:].astype(np.int)\n",
        "\n",
        "#creamos los tensores \n",
        "X_t = torch.from_numpy(X_train).float().cuda()\n",
        "Y_t = torch.from_numpy(y_train).long().cuda()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn5XkMxTdNGX"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# es una funcion generalizadora\n",
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "def evaluate(x):\n",
        "    model.eval()\n",
        "    y_pred = model(x)\n",
        "    y_probas = softmax(y_pred)\n",
        "    return torch.argmax(y_probas, axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuvTD5KydNQx",
        "outputId": "f552cc1b-7813-45f5-a28d-889e97b07010"
      },
      "source": [
        "Capa_Entrada, Capa_Oculta, Capa_Salida = 784, 100, 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(Capa_Entrada, Capa_Oculta),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(Capa_Oculta, Capa_Salida),\n",
        ").to(\"cuda\")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n",
        "\n",
        "epochs = 100\n",
        "log_each = 10\n",
        "l = []\n",
        "model.train()\n",
        "for e in range(1, epochs+1): \n",
        "    \n",
        "    # forward\n",
        "    y_pred = model(X_t)\n",
        "\n",
        "    # loss\n",
        "    loss = criterion(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "    \n",
        "    # ponemos a cero los gradientes\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backprop (calculamos todos los gradientes automáticamente)\n",
        "    loss.backward()\n",
        "\n",
        "    # update de los pesos\n",
        "    optimizer.step()\n",
        "    \n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "        \n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/100 Loss 1.76640\n",
            "Epoch 20/100 Loss 1.48378\n",
            "Epoch 30/100 Loss 1.24717\n",
            "Epoch 40/100 Loss 1.05596\n",
            "Epoch 50/100 Loss 0.92119\n",
            "Epoch 60/100 Loss 0.83264\n",
            "Epoch 70/100 Loss 0.75885\n",
            "Epoch 80/100 Loss 0.70330\n",
            "Epoch 90/100 Loss 0.65592\n",
            "Epoch 100/100 Loss 0.61634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-VEL6wKguIS"
      },
      "source": [
        "## Utilizaremos el Algorimto de mini-batch gradient decent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alyg8T6zdNYJ",
        "outputId": "5e489b1d-3aec-4e14-c6a2-7e4c1e0b3ff5"
      },
      "source": [
        "Capa_Entrada, Capa_Oculta, Capa_Salida = 784, 100, 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(Capa_Entrada, Capa_Oculta),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(Capa_Oculta, Capa_Salida),\n",
        ").to(\"cuda\")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 100\n",
        "log_each = 1\n",
        "l = []\n",
        "model.train()\n",
        "\n",
        "batches = len(X_t) // batch_size\n",
        "\n",
        "for e in range(1, epochs+1): \n",
        "    \n",
        "    _l = []\n",
        "    # iteramos por batches\n",
        "    for b in range(batches):\n",
        "        x_b = X_t[b*batch_size:(b+1)*batch_size]\n",
        "        y_b = Y_t[b*batch_size:(b+1)*batch_size]\n",
        "        \n",
        "        # forward\n",
        "        y_pred = model(x_b)\n",
        "\n",
        "        # loss\n",
        "        loss = criterion(y_pred, y_b)\n",
        "        _l.append(loss.item())\n",
        "\n",
        "        # ponemos a cero los gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backprop (calculamos todos los gradientes automáticamente)\n",
        "        loss.backward()\n",
        "\n",
        "        # update de los pesos\n",
        "        optimizer.step()\n",
        "    \n",
        "    l.append(np.mean(_l))\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "        \n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10 Loss 0.29818\n",
            "Epoch 2/10 Loss 0.20834\n",
            "Epoch 3/10 Loss 0.16724\n",
            "Epoch 4/10 Loss 0.14176\n",
            "Epoch 5/10 Loss 0.12383\n",
            "Epoch 6/10 Loss 0.11018\n",
            "Epoch 7/10 Loss 0.09928\n",
            "Epoch 8/10 Loss 0.09028\n",
            "Epoch 9/10 Loss 0.08279\n",
            "Epoch 10/10 Loss 0.07641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9735"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQpDA3JjjmTh"
      },
      "source": [
        "# La clase Dataset\n",
        "### La primera clase que tenemos que conocer es la clase Dataset. Esta clase hereda de la clase madre torch.utils.data.Dataset y tenemos que definir, como mínimo, tres funciones:\n",
        "\n",
        "- __init__: el constructor\n",
        "- __len__: devuelve el número de muestras en el dataset\n",
        "- __getitem__: devuelve una muestra en concreto del dataset\n",
        "### Una vez definida la clase, ésta puede usarse como si de cualquier iterador se tratase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt3Qk9TEdNdy"
      },
      "source": [
        "# clase Dataset, hereda de la clase `torch.utils.data.Dataset`\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    # constructor\n",
        "    def __init__(self, X, Y): #esta clase Dataset recive como parametros arrays numpy RECORDAR\n",
        "        self.X = torch.from_numpy(X).float().cuda()\n",
        "        self.Y = torch.from_numpy(Y).long().cuda()\n",
        "    \n",
        "    # devolvemos el número de datos en el dataset\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    # devolvemos el elemento `ix` del dataset\n",
        "    def __getitem__(self, ix):\n",
        "        return self.X[ix], self.Y[ix]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBIudONPkiIt",
        "outputId": "e09b7c1f-6405-4fe5-c718-bf7ad5d1aa3a"
      },
      "source": [
        "print(type(X_train))\n",
        "print(type(y_train))\n",
        "\n",
        "dataset = Dataset(X_train,y_train)\n",
        "print(type(dataset))\n",
        "print(\"Este es un tensor de Pytroch recuerdalo ->  \",dataset)\n",
        "print(\"Longitud del Dataset : \",len(dataset))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class '__main__.Dataset'>\n",
            "Este es un tensor de Pytroch recuerdalo ->   <__main__.Dataset object at 0x7f1a248c9c50>\n",
            "Longitud del Dataset :  60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QiqxQ3wlZUz",
        "outputId": "6298f358-5c4a-46d3-d927-574cfd79a619"
      },
      "source": [
        "Capa_Entrada, Capa_Oculta, Capa_Salida = 784, 100, 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(Capa_Entrada, Capa_Oculta),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(Capa_Oculta, Capa_Salida),\n",
        ").to(\"cuda\")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 100\n",
        "log_each = 1\n",
        "l = []\n",
        "model.train()\n",
        "\n",
        "batches = len(dataset) // batch_size\n",
        "\n",
        "for e in range(1, epochs+1): \n",
        "    \n",
        "    _l = []\n",
        "    # iteramos por batches en el dataset\n",
        "    for b in range(batches):\n",
        "        x_b, y_b = dataset[b*batch_size:(b+1)*batch_size]\n",
        "        \n",
        "        # forward\n",
        "        y_pred = model(x_b)\n",
        "\n",
        "        # loss\n",
        "        loss = criterion(y_pred, y_b)\n",
        "        _l.append(loss.item())\n",
        "\n",
        "        # ponemos a cero los gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backprop (calculamos todos los gradientes automáticamente)\n",
        "        loss.backward()\n",
        "\n",
        "        # update de los pesos\n",
        "        optimizer.step()\n",
        "    \n",
        "    l.append(np.mean(_l))\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "        \n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10 Loss 0.30245\n",
            "Epoch 2/10 Loss 0.20993\n",
            "Epoch 3/10 Loss 0.16794\n",
            "Epoch 4/10 Loss 0.14256\n",
            "Epoch 5/10 Loss 0.12466\n",
            "Epoch 6/10 Loss 0.11090\n",
            "Epoch 7/10 Loss 0.09993\n",
            "Epoch 8/10 Loss 0.09087\n",
            "Epoch 9/10 Loss 0.08323\n",
            "Epoch 10/10 Loss 0.07664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFmLZndhmea5"
      },
      "source": [
        "# Clase Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtKq-u81lZhy"
      },
      "source": [
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBfMDiTMlZsK",
        "outputId": "920899fc-6fa4-49c1-b5c7-36494dc8dc3f"
      },
      "source": [
        "# con esto lo iteramos a nuestro data loader y le pedimos el primer batch\n",
        "x, y = next(iter(dataloader))\n",
        "print(type(dataloader))\n",
        "print(len(dataloader))\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.utils.data.dataloader.DataLoader'>\n",
            "600\n",
            "torch.Size([100, 784]) torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRzAcEYZnh0t",
        "outputId": "abd1ef59-6f66-443e-f2f8-7f29dd65fa05"
      },
      "source": [
        "Capa_Entrada, Capa_Oculta, Capa_Salida = 784, 100, 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(Capa_Entrada, Capa_Oculta),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(Capa_Oculta, Capa_Salida),\n",
        ").to(\"cuda\")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n",
        "\n",
        "epochs = 10\n",
        "log_each = 1\n",
        "l = []\n",
        "model.train()\n",
        "for e in range(1, epochs+1): \n",
        "    \n",
        "    _l = []\n",
        "    # iteramos por batches en el dataloader\n",
        "    for x_b, y_b in dataloader:\n",
        "        \n",
        "        # forward\n",
        "        y_pred = model(x_b)\n",
        "\n",
        "        # loss\n",
        "        loss = criterion(y_pred, y_b)\n",
        "        _l.append(loss.item())\n",
        "\n",
        "        # ponemos a cero los gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backprop (calculamos todos los gradientes automáticamente)\n",
        "        loss.backward()\n",
        "\n",
        "        # update de los pesos\n",
        "        optimizer.step()\n",
        "    \n",
        "    l.append(np.mean(_l))\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "        \n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10 Loss 0.30650\n",
            "Epoch 2/10 Loss 0.21272\n",
            "Epoch 3/10 Loss 0.17054\n",
            "Epoch 4/10 Loss 0.14479\n",
            "Epoch 5/10 Loss 0.12681\n",
            "Epoch 6/10 Loss 0.11327\n",
            "Epoch 7/10 Loss 0.10250\n",
            "Epoch 8/10 Loss 0.09355\n",
            "Epoch 9/10 Loss 0.08614\n",
            "Epoch 10/10 Loss 0.07971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdVWUqxupCkS"
      },
      "source": [
        "#También permite definir nuestra propia lógica para crear los batches, algo que puede ser útil en ciertas ocasiones.\n",
        "def collate_fn(batch): #crear nuestros propios batches\n",
        "    return torch.stack([x for x, y in batch]), torch.stack([y for x, y in batch]), torch.stack([2.*x for x, y in batch])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvSwqWCtpChZ"
      },
      "source": [
        "#implementar al dataloader nuestros propios batches creados\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True, collate_fn=collate_fn)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwlipEzNpCeL",
        "outputId": "97d6e030-7736-47e9-9622-a989fc43aa80"
      },
      "source": [
        "Capa_Entrada, Capa_Oculta, Capa_Salida = 784, 100, 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(Capa_Entrada, Capa_Oculta),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(Capa_Oculta, Capa_Salida),\n",
        ").to(\"cuda\")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n",
        "\n",
        "epochs = 10\n",
        "log_each = 1\n",
        "l = []\n",
        "model.train()\n",
        "for e in range(1, epochs+1): \n",
        "    \n",
        "    _l = []\n",
        "    # iteramos por batches en el dataloader\n",
        "    # no usamos x2_b, sólo es para ver un ejemplo\n",
        "    for x_b, y_b, x2_b in dataloader:\n",
        "        \n",
        "        # forward\n",
        "        y_pred = model(x_b)\n",
        "\n",
        "        # loss\n",
        "        loss = criterion(y_pred, y_b)\n",
        "        _l.append(loss.item())\n",
        "\n",
        "        # ponemos a cero los gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backprop (calculamos todos los gradientes automáticamente)\n",
        "        loss.backward()\n",
        "\n",
        "        # update de los pesos\n",
        "        optimizer.step()\n",
        "    \n",
        "    l.append(np.mean(_l))\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "        \n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10 Loss 0.30384\n",
            "Epoch 2/10 Loss 0.21194\n",
            "Epoch 3/10 Loss 0.17112\n",
            "Epoch 4/10 Loss 0.14620\n",
            "Epoch 5/10 Loss 0.12906\n",
            "Epoch 6/10 Loss 0.11575\n",
            "Epoch 7/10 Loss 0.10521\n",
            "Epoch 8/10 Loss 0.09640\n",
            "Epoch 9/10 Loss 0.08923\n",
            "Epoch 10/10 Loss 0.08308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}